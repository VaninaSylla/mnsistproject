# MNIST Classification avec MLflow

Ce projet implÃ©mente un rÃ©seau de neurones dense pour la classification de chiffres manuscrits du dataset MNIST, avec suivi des expÃ©rimentations via MLflow.

## ğŸ“‹ Description

Le modÃ¨le utilise un rÃ©seau de neurones entiÃ¨rement connectÃ© (Dense Neural Network) pour classifier des images de chiffres de 0 Ã  9. MLflow est intÃ©grÃ© pour tracker les hyperparamÃ¨tres, mÃ©triques et modÃ¨les.

## ğŸ—ï¸ Architecture du ModÃ¨le

- **Couche d'entrÃ©e** : 784 neurones (images 28Ã—28 pixels aplaties)
- **Couche cachÃ©e** : 512 neurones avec activation ReLU
- **Dropout** : 20% pour la rÃ©gularisation
- **Couche de sortie** : 10 neurones avec activation Softmax (classification multi-classe)

## ğŸ“¦ PrÃ©requis

```bash
pip install tensorflow numpy mlflow
```

## ğŸš€ Utilisation

### EntraÃ®nement du modÃ¨le

```bash
python mnist_mlflow.py
```

### Visualisation des rÃ©sultats avec MLflow

```bash
mlflow ui
```

Puis ouvrez votre navigateur Ã  l'adresse : `http://localhost:5000`

## âš™ï¸ HyperparamÃ¨tres

| ParamÃ¨tre | Valeur |
|-----------|--------|
| Ã‰poques | 5 |
| Batch size | 128 |
| Validation split | 0.1 (10%) |
| Neurones cachÃ©s | 512 |
| Dropout rate | 0.2 (20%) |
| Optimiseur | Adam |
| Loss | Sparse Categorical Crossentropy |

## ğŸ“Š MÃ©triques Suivies

Le script enregistre automatiquement dans MLflow :

- **HyperparamÃ¨tres** : nombre d'Ã©poques, batch size, architecture, etc.
- **MÃ©triques d'entraÃ®nement** : loss et accuracy par Ã©poque
- **MÃ©triques de validation** : val_loss et val_accuracy par Ã©poque
- **MÃ©triques de test** : test_loss et test_accuracy finales
- **ModÃ¨le** : sauvegarde au format MLflow et H5

## ğŸ“ˆ RÃ©sultats Attendus

Le modÃ¨le devrait atteindre une prÃ©cision d'environ **97-98%** sur le jeu de test aprÃ¨s 5 Ã©poques.

## ğŸ“ Structure du Projet

```
.
â”œâ”€â”€ mnist_mlflow.py          # Script principal d'entraÃ®nement
â”œâ”€â”€ mnist_model.h5           # ModÃ¨le sauvegardÃ© (gÃ©nÃ©rÃ©)
â”œâ”€â”€ mlruns/                  # Dossier MLflow (gÃ©nÃ©rÃ©)
â””â”€â”€ README.md                # Ce fichier
```

## ğŸ” FonctionnalitÃ©s MLflow

### ExpÃ©rimentation
- Nom de l'expÃ©rience : `MNIST_Classification`
- Enregistrement automatique de tous les hyperparamÃ¨tres
- Tracking des mÃ©triques Ã  chaque Ã©poque

### ModÃ¨le Registry
- Le modÃ¨le est enregistrÃ© sous le nom : `MNIST_DNN_Model`
- Signature du modÃ¨le infÃ©rÃ©e automatiquement
- Format compatible pour le dÃ©ploiement

### Tags
- `model_type`: Dense Neural Network
- `dataset`: MNIST
- `framework`: TensorFlow/Keras

## ğŸ¯ Utilisation du ModÃ¨le SauvegardÃ©

### Chargement avec MLflow

```python
import mlflow.keras

# Charger le modÃ¨le
model = mlflow.keras.load_model("runs:/<RUN_ID>/model")

# Faire des prÃ©dictions
predictions = model.predict(x_test)
```

### Chargement avec Keras

```python
from tensorflow import keras

model = keras.models.load_model('mnist_model.h5')
predictions = model.predict(x_test)
```

## ğŸ› ï¸ Personnalisation

Vous pouvez modifier les hyperparamÃ¨tres au dÃ©but du script :

```python
epochs = 5
batch_size = 128
hidden_units = 512
dropout_rate = 0.2
```

## ğŸ“ Notes

- Les donnÃ©es MNIST sont automatiquement tÃ©lÃ©chargÃ©es par Keras
- Le modÃ¨le est normalisÃ© (pixels entre 0 et 1)
- La validation split de 10% est appliquÃ©e automatiquement
- Tous les rÃ©sultats sont trackÃ©s dans le dossier `mlruns/`

## ğŸ¤ Contribution

Pour amÃ©liorer le modÃ¨le, vous pouvez :
- Ajuster les hyperparamÃ¨tres
- Ajouter des couches cachÃ©es supplÃ©mentaires
- Tester diffÃ©rents optimiseurs
- ImplÃ©menter l'early stopping

## ğŸ“œ Licence

Ce projet est Ã  des fins Ã©ducatives dans le cadre d'un TP de Deep Learning.